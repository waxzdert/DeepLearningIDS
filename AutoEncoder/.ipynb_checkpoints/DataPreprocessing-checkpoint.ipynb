{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "file_dict = {\n",
    "    'Train':'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDTrain+.csv',\n",
    "    'Test':'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDTest+.csv',\n",
    "    'Minus21':'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDTest-21.csv'\n",
    "}\n",
    "\n",
    "#計算資料的特徵中有多少獨立項\n",
    "#print(raw_data.groupby('protocol_type').ngroups)\n",
    "#print(raw_data.groupby('Service').ngroups)\n",
    "#print(raw_data.groupby('flag').ngroups)\n",
    "\n",
    "\n",
    "#================== OneHot Encoding ==================\n",
    "def one_hot(in_df):\n",
    "\n",
    "    # Convert some nonnumeric features into numeric form\n",
    "    # Example: protocol_type, service and flag\n",
    "\n",
    "    #將prorocol type 轉換為數值, dim: 41->44, (125973, 44)\n",
    "    oh_df = pd.get_dummies(data=in_df, columns=['protocol_type'])\n",
    "    #將Service轉換為數值, dim: 44->112, (125973, 112)\n",
    "    oh_df = pd.get_dummies(data=oh_df, columns=['Service'])\n",
    "    #將flag轉換為數值, dim: 112->122,(125973, 122)\n",
    "    oh_df = pd.get_dummies(data=oh_df, columns=['flag'])\n",
    "    return oh_df\n",
    "\n",
    "#================== Normalization ==================\n",
    "def fir_norm(in_df):\n",
    "    # Normalize the data which difference between maximum and minimum values\n",
    "    # such as : ‘duration[0,58329]’,‘src_bytes[0,1.3 × 109]’ and ‘dst_bytes\n",
    "    # Logarithmic scaling method for scaling to obtain the ranges\n",
    "    # (x,y) -> (log(x),log(y))\n",
    "    for i in range(len(in_df['Duration'])):\n",
    "        if (in_df.loc[i,('Duration')]) == 0:\n",
    "            in_df.loc[i,('Duration')] = 0\n",
    "        else:\n",
    "            in_df.loc[i,('Duration')] = round(math.log(in_df.loc[i,('Duration')],10), 2)\n",
    "\n",
    "    for i in range(len(in_df['src_bytes'])):\n",
    "        if (in_df.loc[i,('src_bytes')]) == 0:\n",
    "            in_df.loc[i,('src_bytes')] = 0\n",
    "        else:\n",
    "            in_df.loc[i,('src_bytes')] = round(math.log(in_df.loc[i,('src_bytes')],10), 2)\n",
    "\n",
    "    for i in range(len(in_df['dst_bytes'])):\n",
    "        if (in_df.loc[i,('dst_bytes')]) == 0:\n",
    "            in_df.loc[i,('dst_bytes')] = 0\n",
    "        else:\n",
    "            in_df.loc[i,('dst_bytes')] = round(math.log(in_df.loc[i,('dst_bytes')],10), 2)\n",
    "\n",
    "def sec_norm(in_df):\n",
    "    # Normalize all the data in the dataframe\n",
    "    # let the data in the frame can \n",
    "    # new Xi = ((old Xi)-min)/(Max-min)\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    # remove the feature with string which can't normalize\n",
    "    temp_data = in_df.drop('result', axis=1)\n",
    "\n",
    "    # let data transform the type from dataframe to numpy array\n",
    "    temp_data = temp_data.values\n",
    "\n",
    "    # Define a scaler that will feed nraw data afterward\n",
    "    # The scaler will normalize the data into new Xi = ((old Xi)-min)/(Max-min)\n",
    "    # And it's output will range from 0 to 1.\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    # feed the data to the scaler\n",
    "    temp_data = scaler.fit_transform(temp_data)\n",
    "\n",
    "    # Transfer the numpy array to dataframe\n",
    "    temp_data = pd.DataFrame(temp_data)\n",
    "\n",
    "    # merge the feature which remove first\n",
    "    temp_data = temp_data.join(in_df[['result']])\n",
    "\n",
    "    return temp_data\n",
    "\n",
    "def ren_idx(new_df, old_df):\n",
    "    # This function main use to rename the index of the dataset\n",
    "    temp = []\n",
    "    for i in range(1,len(old_df.columns)):\n",
    "        temp.append(old_df.columns[i])\n",
    "    temp.append(old_df.columns[0])\n",
    "    new_df.columns = temp\n",
    "\n",
    "def label_trans(in_df):\n",
    "    # 1 represent the traffic is an attack\n",
    "    # 0 represent the traffic is a normal traffic\n",
    "    dos = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop']\n",
    "    u2r = ['buffer_overflow', 'loadmodule', 'perl', 'rootkit', ]\n",
    "    r2l = ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster']\n",
    "    probe = ['ipsweep', 'nmap', 'portsweep', 'satan'] \n",
    "    \n",
    "    attack_count = [0, 0, 0, 0, 0]\n",
    "    # attack_count = [dos, u2r, r2l, probe, normal]\n",
    "    \n",
    "    for i in range(len(in_df['result'])):\n",
    "        if(in_df.loc[i,('result')] in dos):\n",
    "            in_df.loc[i,('result')] = 'dos'\n",
    "            attack_count[0] = attack_count[0] + 1\n",
    "            \n",
    "        elif(in_df.loc[i,('result')] in u2r):\n",
    "            in_df.loc[i,('result')] = 'u2r'\n",
    "            attack_count[1] = attack_count[1] + 1\n",
    "            \n",
    "        elif(in_df.loc[i,('result')] in r2l):\n",
    "            in_df.loc[i,('result')] = 'r2l'\n",
    "            attack_count[2] = attack_count[2] + 1\n",
    "            \n",
    "        elif(in_df.loc[i,('result')] in 'probe'):\n",
    "            in_df.loc[i,('result')] = 'probe'\n",
    "            attack_count[3] = attack_count[3] + 1\n",
    "        else:\n",
    "            attack_count[4] = attack_count[4] + 1\n",
    "\n",
    "def execute(raw_data, idx):\n",
    "    OneHotData = one_hot(raw_data)\n",
    "    fir_norm(OneHotData)\n",
    "    Processed_Data = sec_norm(OneHotData)\n",
    "    ren_idx(Processed_Data, OneHotData)\n",
    "    label_trans(Processed_Data)\n",
    "    Processed_Data.to_csv('Processed_Data_%s.csv' % (idx),index=False,index_label=False)\n",
    "\n",
    "train_data = pd.read_csv(file_dict['Train'])\n",
    "execute(train_data, 'Train_dos')\n",
    "\n",
    "test_data = pd.read_csv(file_dict['Test'])\n",
    "execute(test_data, 'Test_dos')\n",
    "\n",
    "Minus21 = pd.read_csv(file_dict['Minus21'])\n",
    "execute(Minus21, 'Minus21_dos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_trf = [1,2,3,'back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GG\n"
     ]
    }
   ],
   "source": [
    "if rand_trf[3] in Dos:\n",
    "    print('GG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
