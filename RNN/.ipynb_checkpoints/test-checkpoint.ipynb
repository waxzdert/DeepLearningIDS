{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib as plt\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(9)\n",
    "#計算程式執行時間\n",
    "StartTime = time.time()\n",
    "\n",
    "# Define the Preprocess function(input the raw csv files)\n",
    "def Data_Preprocess(raw_data):\n",
    "    #This function is main use to process the data for feed into the deep neural network\n",
    "\n",
    "    #do the one hot encodeing,make the non-numeric features to numeric features\n",
    "    data_one_hot = pd.get_dummies(data=raw_data, columns=[\"protocol_type\"])\n",
    "    data_one_hot = pd.get_dummies(data=data_one_hot, columns=[\"Service\"])\n",
    "    data_one_hot = pd.get_dummies(data=data_one_hot, columns=[\"flag\"])\n",
    "\n",
    "    #turn data list to data array\n",
    "    data_array = data_one_hot.values\n",
    "\n",
    "    #find the 'normal' label index that can do the replacement of this feature.   result label index:0\n",
    "    '''i, = np.where(data_array[0]=='normal')'''\n",
    "\n",
    "    #transfer the result to numeric type\n",
    "    for x in range(len(data_array)):\n",
    "        if data_array[x][0]!='normal.':\n",
    "            data_array[x][0]=1\n",
    "        else:\n",
    "            data_array[x][0]=0\n",
    "\n",
    "    #output the shape of the numpy data array\n",
    "    '''print(data_array.shape)'''\n",
    "\n",
    "    #output all of the label \n",
    "    Label = data_array[:,0]\n",
    "    #output all of the feature\n",
    "    Features = data_array[:,1:]\n",
    "    \n",
    "    #Normalization\n",
    "    #import the module \n",
    "    '''\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    #use the preprocessing that can normalize the feature \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    #make the features transfer to 0~1\n",
    "    scaled_Features = minmax_scale.fit_transform(Features)\n",
    "    \n",
    "    return scaled_Features, Label\n",
    "    '''\n",
    "    return Features, Label\n",
    "\n",
    "#讀入檔案\n",
    "#file_name = 'C:\\\\Users\\Maxwu\\Desktop\\Tensorflow_works\\Datasets\\\\NSL_KDD\\KDDTrain+_Preprocess.xlsx'\n",
    "#讀入檔案切割其中1000筆來測試\n",
    "#file_name = '//Users/wudongye/Desktop/DeepLearningIDS/Datasets/KDDTrain+_Raw_1000.csv'#in OSX\n",
    "file_name = 'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDcombined+_Raw.csv'#in Windows\n",
    "#file_name = '//Users/wudongye/Documents/GitHub/DeepLearningIDS/Datasets/KDDTrain+_Raw_1000.csv' #in OSX\n",
    "all_data = pd.read_csv(file_name)\n",
    "\n",
    "all_Features, all_Label = Data_Preprocess(all_data)\n",
    "mask = np.random.rand(len(all_data)) < 0.8\n",
    "train_Features = all_Features[mask]\n",
    "train_Label = all_Label[mask]\n",
    "test_Features = all_Features[~mask]\n",
    "test_Label = all_Label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape is : (395224, 119)\n",
      "Train Y shape is : (395224,)\n",
      "Test X shape is : (98797, 119)\n",
      "Test Y shape is : (98797,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train X shape is :\", train_Features.shape)\n",
    "print (\"Train Y shape is :\", train_Label.shape)\n",
    "print (\"Test X shape is :\", test_Features.shape)\n",
    "print (\"Test Y shape is :\", test_Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_classes = 1\n",
    "display_step = 100\n",
    "training_cycles = 1000\n",
    "hidden_units = 3\n",
    "input_features = 119\n",
    "time_steps = 1\n",
    "batch_size = 47031656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 47031656 into shape (47031656,1,119)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1156538dce25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m47031656\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnewtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m47031656\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewtrain_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 47031656 into shape (47031656,1,119)"
     ]
    }
   ],
   "source": [
    "newtrain_X = train_Features.reshape(len(train_Feature), time_steps, input_features)\n",
    "newtrain_Y = train_Label.reshape(len(train_Label), n_classes)\n",
    "print(newtrain_X.shape)\n",
    "print(newtrain_Y.shape)\n",
    "print(len(train_Features))\n",
    "print(len(train_Label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, time_steps, input_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "#Weights and Biases\n",
    "weights = {\n",
    "    # (1, 3)\n",
    "    'in': tf.Variable(tf.random_normal([time_steps, hidden_units])),\n",
    "    # (3, 1)\n",
    "    'out': tf.Variable(tf.random_normal([hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # (3, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[hidden_units, ])),\n",
    "    # (1, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights['in'].shape)\n",
    "print(weights['out'].shape)\n",
    "print(biases['in'].shape)\n",
    "print(biases['out'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X, weights, biases):\n",
    "    print(X.shape)\n",
    "    X = tf.reshape(X, [-1, time_steps])\n",
    "    print(X.shape)\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    print(X_in.shape)\n",
    "    X_in = tf.reshape(X_in, [-1, time_steps, hidden_units])\n",
    "    print(X_in.shape)\n",
    "    \n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "    init_state = cell.zero_state(len(newtrain_X), dtype=tf.float32)\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)\n",
    "    print(outputs.shape)\n",
    "    print(outputs[-1].shape)\n",
    "    outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "    #print(outputs.shape)\n",
    "    print(outputs[-1].shape)\n",
    "    results = tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "    print(results.shape)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1000):\n",
    "    sess.run([train_op], feed_dict = {x:newtrain_X, y:newtrain_Y})\n",
    "    \n",
    "    if (i) % 100 == 0:\n",
    "        print (\"Cost for the training cycle : \",i,\" : is : \",sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "correct = tf.equal(tf.argmax(output, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "print('Accuracy on the overall test set is :',accuracy.eval({x:newtest_X, y:newtest_Y}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
