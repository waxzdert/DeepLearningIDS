{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib as plt\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(9)\n",
    "#計算程式執行時間\n",
    "StartTime = time.time()\n",
    "\n",
    "# Define the Preprocess function(input the raw csv files)\n",
    "def Data_Preprocess(raw_data):\n",
    "    #This function is main use to process the data for feed into the deep neural network\n",
    "\n",
    "    #do the one hot encodeing,make the non-numeric features to numeric features\n",
    "    data_one_hot = pd.get_dummies(data=raw_data, columns=[\"protocol_type\"])\n",
    "    data_one_hot = pd.get_dummies(data=data_one_hot, columns=[\"Service\"])\n",
    "    data_one_hot = pd.get_dummies(data=data_one_hot, columns=[\"flag\"])\n",
    "\n",
    "    #turn data list to data array\n",
    "    data_array = data_one_hot.values\n",
    "\n",
    "    #find the 'normal' label index that can do the replacement of this feature.   result label index:0\n",
    "    '''i, = np.where(data_array[0]=='normal')'''\n",
    "\n",
    "    #transfer the result to numeric type\n",
    "    for x in range(len(data_array)):\n",
    "        if data_array[x][0]!='normal.':\n",
    "            data_array[x][0]=1\n",
    "        else:\n",
    "            data_array[x][0]=0\n",
    "\n",
    "    #output the shape of the numpy data array\n",
    "    '''print(data_array.shape)'''\n",
    "\n",
    "    #output all of the label \n",
    "    Label = data_array[:,0]\n",
    "    #output all of the feature\n",
    "    Features = data_array[:,1:]\n",
    "    \n",
    "    #Normalization\n",
    "    #import the module \n",
    "    '''\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    #use the preprocessing that can normalize the feature \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    #make the features transfer to 0~1\n",
    "    scaled_Features = minmax_scale.fit_transform(Features)\n",
    "    \n",
    "    return scaled_Features, Label\n",
    "    '''\n",
    "    return Features, Label\n",
    "\n",
    "#讀入檔案\n",
    "#file_name = 'C:\\\\Users\\Maxwu\\Desktop\\Tensorflow_works\\Datasets\\\\NSL_KDD\\KDDTrain+_Preprocess.xlsx'\n",
    "#讀入檔案切割其中1000筆來測試\n",
    "#file_name = '//Users/wudongye/Desktop/DeepLearningIDS/Datasets/KDDTrain+_Raw_1000.csv'#in OSX\n",
    "#file_name = 'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDcombined+_Raw.csv'#in Windows\n",
    "file_name = 'C:\\\\Users\\\\MaxWu\\\\Documents\\\\GitHub\\\\DeepLearningIDS\\\\Datasets\\\\KDDTrain+_Raw_1000.csv'\n",
    "#file_name = '//Users/wudongye/Documents/GitHub/DeepLearningIDS/Datasets/KDDTrain+_Raw_1000.csv' #in OSX\n",
    "all_data = pd.read_csv(file_name)\n",
    "\n",
    "all_Features, all_Label = Data_Preprocess(all_data)\n",
    "mask = np.random.rand(len(all_data)) < 0.8\n",
    "train_Features = all_Features[mask]\n",
    "train_Label = all_Label[mask]\n",
    "test_Features = all_Features[~mask]\n",
    "test_Label = all_Label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape is : (809, 107)\n",
      "Train Y shape is : (809,)\n",
      "Test X shape is : (191, 107)\n",
      "Test Y shape is : (191,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train X shape is :\", train_Features.shape)\n",
    "print (\"Train Y shape is :\", train_Label.shape)\n",
    "print (\"Test X shape is :\", test_Features.shape)\n",
    "print (\"Test Y shape is :\", test_Label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_classes = 1\n",
    "display_step = 100\n",
    "input_features = 107 #No of selected features(columns)\n",
    "training_cycles = 1000\n",
    "time_steps = 1 # No of time-steps to backpropogate\n",
    "hidden_units = 3 #No of LSTM units in a LSTM Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 1, 107)\n",
      "(809, 1)\n"
     ]
    }
   ],
   "source": [
    "newtrain_X = train_Features.reshape(len(train_Features), time_steps, input_features)\n",
    "newtrain_Y = train_Label.reshape(len(train_Label), n_classes)\n",
    "print(newtrain_X.shape)\n",
    "print(newtrain_Y.shape)\n",
    "#print(newtrain_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 107)\n",
      "(?, 1)\n",
      "(3, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#Input Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, time_steps, input_features], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='y-input')\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "#Weights and Biases\n",
    "weight = tf.Variable(tf.random_normal([hidden_units, n_classes]), name='weight')\n",
    "bias = tf.Variable(tf.random_normal(shape=[n_classes]), name='bias')\n",
    "print(weight.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:0\", shape=(?, 3), dtype=float32)\n",
      "(3, 1)\n",
      "(?, 1)\n",
      "Tensor(\"add:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "init_state = cell.zero_state(len(newtrain_X), dtype=tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "results = tf.matmul(outputs[-1], weight) + bias\n",
    "print(outputs[-1])\n",
    "print(weight.shape)\n",
    "print(results.shape)\n",
    "print(results)\n",
    "#print(results.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ce01287d66a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxwu\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2036\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   2037\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2038\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   2039\u001b[0m     \u001b[1;31m# Check if no reshapes are required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2)."
     ]
    }
   ],
   "source": [
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=results, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(results, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b583cd7b268e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mnewtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mnewtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mnewtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "print(sess.run(results[0:5], feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "print(sess.run(y[0:5], feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "    \n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits_v2(logits=results, labels=y), feed_dict ={x :newtrain_X,y:newtrain_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range (1000):\n",
    "#    sess.run([train_op], feed_dict = {x:newtrain_X, y:newtrain_Y})\n",
    "#    if (i) % 100 == 0:\n",
    "#        print (\"Cost for the training cycle : \",i,\" : is : \",sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "#correct = tf.equal(tf.argmax(results, 1), tf.argmax(y,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "#print('Accuracy on the overall test set is :',accuracy.eval({x:newtest_X, y:newtest_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
