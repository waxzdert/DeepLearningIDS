{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maxwu\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training file path\n",
    "file_dict = {\n",
    "    'Train':'Processed_Data_Train.csv',\n",
    "    'Test':'Processed_Data_Test.csv',\n",
    "    'Minus21':'Processed_Data_Minus21.csv'\n",
    "}\n",
    "train_data = pd.read_csv(file_dict['Train'])\n",
    "test_data = pd.read_csv(file_dict['Test'])\n",
    "minus_data = pd.read_csv(file_dict['Minus21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fl(data):\n",
    "    # This function mainly to transfer the raw csv file to \n",
    "    # training features and labels. \n",
    "    \n",
    "    # Select the features in the input data\n",
    "    features = data[:, 0:122]\n",
    "    # Select the labels in the input data\n",
    "    labels = data[:, 122]\n",
    "    #trans the label from text to\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.values\n",
    "test_data = test_data.values\n",
    "minus_data = minus_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training features and labels \n",
    "train_Features, train_Labels = parse_fl(train_data)\n",
    "test_Features, test_Labels = parse_fl(test_data)\n",
    "minus_Features, minus_Labels = parse_fl(minus_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = []\n",
    "\n",
    "for i in range(len(train_Labels)):\n",
    "    if (train_Labels[i] == 1):\n",
    "        temp_labels.append([1, 0])\n",
    "    else:\n",
    "        temp_labels.append([0, 1])\n",
    "\n",
    "train_Labels = temp_labels\n",
    "train_Labels = np.array(train_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = []\n",
    "\n",
    "for i in range(len(test_Labels)):\n",
    "    if (test_Labels[i] == 1):\n",
    "        temp_labels.append([1, 0])\n",
    "    else:\n",
    "        temp_labels.append([0, 1])\n",
    "\n",
    "test_Labels = temp_labels\n",
    "test_Labels = np.array(test_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = []\n",
    "\n",
    "for i in range(len(minus_Labels)):\n",
    "    if (minus_Labels[i] == 1):\n",
    "        temp_labels.append([1, 0])\n",
    "    else:\n",
    "        temp_labels.append([0, 1])\n",
    "\n",
    "minus_Labels = temp_labels\n",
    "minus_Labels = np.array(minus_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_classes = 2\n",
    "display_step = 10\n",
    "training_cycles = 100\n",
    "hidden_units = 20\n",
    "input_features = 122\n",
    "time_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain_X = train_Features.reshape(len(train_Features), time_steps, -1)\n",
    "newtrain_Y = train_Labels.reshape(len(train_Labels), n_classes)\n",
    "\n",
    "newtest_X = test_Features.reshape(len(test_Features), time_steps, -1)\n",
    "newtest_Y = test_Labels.reshape(len(test_Labels), n_classes)\n",
    "\n",
    "newminus_X = minus_Features.reshape(len(minus_Features), time_steps, -1)\n",
    "newminus_Y = minus_Labels.reshape(len(minus_Labels), n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, time_steps, input_features], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.random_normal([hidden_units, n_classes]), name='weight')\n",
    "bias = tf.Variable(tf.random_normal(shape=[n_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "init_state = cell.zero_state(len(newtrain_X), dtype=tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "results = tf.matmul(outputs[-1], weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=results, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(results, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for the training cycle :  0  : is :  0.9830913\n",
      "Cost for the training cycle :  10  : is :  0.15964782\n",
      "Cost for the training cycle :  20  : is :  0.14005461\n",
      "Cost for the training cycle :  30  : is :  0.12121737\n",
      "Cost for the training cycle :  40  : is :  0.10577801\n",
      "Cost for the training cycle :  50  : is :  0.09539103\n",
      "Cost for the training cycle :  60  : is :  0.08983828\n",
      "Cost for the training cycle :  70  : is :  0.08668803\n",
      "Cost for the training cycle :  80  : is :  0.08384562\n",
      "Cost for the training cycle :  90  : is :  0.08130665\n"
     ]
    }
   ],
   "source": [
    "for i in range (training_cycles):\n",
    "    _,c = sess.run([optimizer,cost], feed_dict = {x:newtrain_X, y:newtrain_Y})\n",
    "    \n",
    "    if (i) % display_step == 0:\n",
    "        print (\"Cost for the training cycle : \",i,\" : is : \",sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the overall train set is : 92.0654721558094 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the overall train set is :',(1-(sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y})))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time is: 105 sec\n"
     ]
    }
   ],
   "source": [
    "print('Training time is: %d sec' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the overall test set is : 74.302444 %\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.argmax(results, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))*100\n",
    "\n",
    "print('Accuracy on the overall test set is :',accuracy.eval({x:newtest_X, y:newtest_Y}),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the overall minus set is : 51.265823 %\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.argmax(results, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))*100\n",
    "\n",
    "print('Accuracy on the overall minus set is :',accuracy.eval({x:newminus_X, y:newminus_Y}),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.argmax = Returns the index with the largest value across axes of a tensor.\n",
    "# Therefore, we are extracting the final labels => '1 0' = '1' = Normal (and vice versa)\n",
    "# Steps to calculate the confusion matrix\n",
    "\n",
    "pred_class = sess.run(tf.argmax(results,1),feed_dict = {x:newtest_X,y:newtest_Y})\n",
    "labels_class = sess.run(tf.argmax(y,1),feed_dict = {x:newtest_X,y:newtest_Y})\n",
    "conf = tf.contrib.metrics.confusion_matrix(labels_class,pred_class,dtype = tf.int32)\n",
    "ConfM = sess.run(conf, feed_dict={x:newtest_X,y:newtest_Y})\n",
    "print (\"confusion matrix \\n\",ConfM)\n",
    "\n",
    "#Plotting the Confusion Matrix\n",
    "labels = ['Normal', 'Attack']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(ConfM)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy through another procedure\n",
    "n = tf.cast(labels_class,tf.int64)\n",
    "newaccuracy = tf.contrib.metrics.accuracy(pred_class,n)\n",
    "print (\"accuracy calcualted using tf.contrib\", sess.run (newaccuracy, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Calculations performed manually for other metrics\n",
    "TP = conf[0,0]\n",
    "FN = conf [0,1]\n",
    "FP = conf[1,0]\n",
    "TN = conf[1,1]\n",
    "\n",
    "AccConf = (TP+TN)/(TP+FP+TN+FN)\n",
    "print (\"Accuracy calculated manually through confusion matrix\", sess.run (AccConf, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Precision\n",
    "Precision = TP/(TP+FP)\n",
    "print (\"Precision \\n\",sess.run(Precision,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Recall also known as Sensitivity\n",
    "Recall = TP/(TP+FN)\n",
    "print (\"Recall (DR) - Sensitivity [True Positive Rate]\\n\", sess.run(Recall,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Specificity\n",
    "\n",
    "Specificity = TN/(TN+FP)\n",
    "print (\"Specificity \\n\", sess.run(Specificity,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#F score\n",
    "FScore = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"F1 Score is \\n\",sess.run(FScore,{x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#False Alarm Rate\n",
    "FAR = FP/(FP+TN)\n",
    "print (\"False Alarm Rate also known as False Positive Rate \\n\",sess.run(FAR,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Efficiency\n",
    "Efficiency = Recall/FAR\n",
    "print(\"Efficincy is \\n\",sess.run(Efficiency,feed_dict = {x:newtest_X,y:newtest_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
