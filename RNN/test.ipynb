{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maxwu\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training file path\n",
    "file_path = 'Processed_Data.csv'\n",
    "raw_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fl(data):\n",
    "    # This function mainly to transfer the raw csv file to \n",
    "    # training features and labels. \n",
    "    \n",
    "    # Select the features in the input data\n",
    "    features = data[:, 0:122]\n",
    "    # Select the labels in the input data\n",
    "    labels = data[:, 122]\n",
    "    #trans the label from text to\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training features and labels \n",
    "train_features, train_labels = parse_fl(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_labels = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    if (train_labels[i] == 1):\n",
    "        temp_labels.append([1, 0])\n",
    "    else:\n",
    "        temp_labels.append([0, 1])\n",
    "\n",
    "train_labels = temp_labels\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_classes = 2\n",
    "display_step = 10\n",
    "training_cycles = 100\n",
    "hidden_units = 20\n",
    "input_features = 122\n",
    "time_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain_X = train_features.reshape(len(train_features), time_steps, -1)\n",
    "newtrain_Y = train_labels.reshape(len(train_labels), n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 122)\n",
      "(125973, 1, 122)\n",
      "(125973, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 122)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, time_steps, input_features], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.Variable(tf.random_normal([hidden_units, n_classes]), name='weight')\n",
    "bias = tf.Variable(tf.random_normal(shape=[n_classes]), name='bias')\n",
    "print(weight.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:0\", shape=(?, 20), dtype=float32)\n",
      "(20, 2)\n",
      "(?, 2)\n",
      "Tensor(\"add:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "init_state = cell.zero_state(len(newtrain_X), dtype=tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "results = tf.matmul(outputs[-1], weight) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=results, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(results, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for the training cycle :  0  : is :  0.61651224\n",
      "Cost for the training cycle :  10  : is :  0.13260826\n",
      "Cost for the training cycle :  20  : is :  0.1134961\n",
      "Cost for the training cycle :  30  : is :  0.101827495\n",
      "Cost for the training cycle :  40  : is :  0.09326477\n",
      "Cost for the training cycle :  50  : is :  0.0881147\n",
      "Cost for the training cycle :  60  : is :  0.08493735\n",
      "Cost for the training cycle :  70  : is :  0.0823467\n",
      "Cost for the training cycle :  80  : is :  0.08014731\n",
      "Cost for the training cycle :  90  : is :  0.07828935\n"
     ]
    }
   ],
   "source": [
    "for i in range (training_cycles):\n",
    "    _,c = sess.run([optimizer,cost], feed_dict = {x:newtrain_X, y:newtrain_Y})\n",
    "    \n",
    "    if (i) % display_step == 0:\n",
    "        print (\"Cost for the training cycle : \",i,\" : is : \",sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newtest_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4708f1a71118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy on the overall test set is :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnewtest_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'newtest_X' is not defined"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.argmax(outputs, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "print('Accuracy on the overall test set is :',accuracy.eval({x:newtrain_X, y:newtrain_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy through another procedure\n",
    "n = tf.cast(labels_class,tf.int64)\n",
    "newaccuracy = tf.contrib.metrics.accuracy(pred_class,n)\n",
    "print (\"accuracy calcualted using tf.contrib\", sess.run (newaccuracy, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Calculations performed manually for other metrics\n",
    "TP = conf[0,0]\n",
    "FN = conf [0,1]\n",
    "FP = conf[1,0]\n",
    "TN = conf[1,1]\n",
    "\n",
    "AccConf = (TP+TN)/(TP+FP+TN+FN)\n",
    "print (\"Accuracy calculated manually through confusion matrix\", sess.run (AccConf, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Precision\n",
    "Precision = TP/(TP+FP)\n",
    "print (\"Precision \\n\",sess.run(Precision,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Recall also known as Sensitivity\n",
    "Recall = TP/(TP+FN)\n",
    "print (\"Recall (DR) - Sensitivity [True Positive Rate]\\n\", sess.run(Recall,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Specificity\n",
    "\n",
    "Specificity = TN/(TN+FP)\n",
    "print (\"Specificity \\n\", sess.run(Specificity,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#F score\n",
    "FScore = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"F1 Score is \\n\",sess.run(FScore,{x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#False Alarm Rate\n",
    "FAR = FP/(FP+TN)\n",
    "print (\"False Alarm Rate also known as False Positive Rate \\n\",sess.run(FAR,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Efficiency\n",
    "Efficiency = Recall/FAR\n",
    "print(\"Efficincy is \\n\",sess.run(Efficiency,feed_dict = {x:newtest_X,y:newtest_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
