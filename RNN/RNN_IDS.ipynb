{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maxwu\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() #the time when program start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training file path\n",
    "file_path = 'Processed_Data.csv'\n",
    "raw_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fl(data):\n",
    "    # This function mainly to transfer the raw csv file to \n",
    "    # training features and labels. \n",
    "    \n",
    "    # Select the features in the input data\n",
    "    features = data[:, 0:122]\n",
    "    # Select the labels in the input data\n",
    "    labels = data[:, 122]\n",
    "    #trans the label from text to\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training features and labels \n",
    "train_features, train_labels = parse_fl(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_classes = 1\n",
    "display_step = 100\n",
    "training_cycles = 1000\n",
    "hidden_units = 1\n",
    "input_features = 122\n",
    "time_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain_X = train_features.reshape(len(train_features), time_steps, -1)\n",
    "newtrain_Y = train_labels.reshape(len(train_labels), n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 122)\n",
      "(125973, 1, 122)\n",
      "(125973, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(newtrain_X.shape)\n",
    "print(newtrain_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 122)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, time_steps, input_features], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='y-input')\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.Variable(tf.random_normal([hidden_units, n_classes]), name='weight')\n",
    "bias = tf.Variable(tf.random_normal(shape=[n_classes]), name='bias')\n",
    "print(weight.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:0\", shape=(?, 1), dtype=float32)\n",
      "(1, 1)\n",
      "(?, 1)\n",
      "Tensor(\"add:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "init_state = cell.zero_state(len(newtrain_X), dtype=tf.float32)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "results = tf.matmul(outputs[-1], weight) + bias\n",
    "print(outputs[-1])\n",
    "print(weight.shape)\n",
    "print(results.shape)\n",
    "print(results)\n",
    "#print(results.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'weight:0' shape=(1, 1) dtype=float32_ref>\", \"<tf.Variable 'bias:0' shape=(1,) dtype=float32_ref>\", \"<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(123, 1) dtype=float32_ref>\", \"<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(1,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e7df597771a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxwu\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    404\u001b[0m           \u001b[1;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m           \u001b[1;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'weight:0' shape=(1, 1) dtype=float32_ref>\", \"<tf.Variable 'bias:0' shape=(1,) dtype=float32_ref>\", \"<tf.Variable 'rnn/basic_rnn_cell/kernel:0' shape=(123, 1) dtype=float32_ref>\", \"<tf.Variable 'rnn/basic_rnn_cell/bias:0' shape=(1,) dtype=float32_ref>\"] and loss Tensor(\"L2Loss:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(results, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range (5):\n",
    "    print(sess.run(results[i], feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "    print(sess.run(y[i], feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "    \n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits_v2(logits=results, labels=y, dim=1), feed_dict ={x :newtrain_X,y:newtrain_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
